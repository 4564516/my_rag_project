id,question,answer,answer_value,answer_unit,ref_id,ref_url,supporting_materials,explanation
,What is the name of the benchmark suite presented in a recent paper for measuring inference energy consumption?,The name of the benchmark suite presented in a recent paper for measuring inference energy consumption is,ML.ENERGY Benchmark,is_blank,['chung2025'],is_blank,,
,What were the net CO2e emissions from training the GShard-600B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,What is the model size in gigabytes (GB) for the LLaMA-33B model?,The model size for LLaMA-33B is 64.7 GB.,64.7,GB,['li2025a'],is_blank,,
,"What was the total electricity consumption of all Google Cloud TPU pods worldwide in 2023, in megawatt-hours?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,True or False: Hyperscale data centers in 2020 achieved more than 40% higher efficiency compared to traditional data centers.,TRUE,1,is_blank,"['wu2021b', 'patterson2021']",is_blank,,
,"For every medium-length GPT-3 completion (prompt= 800 words; response 150 - 300 words), roughly how many 500 mL bottles of water does the model 'drink'?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,"From a sample of 60 papers from top AI conferences, what is the difference between the percentage of CVPR papers that target accuracy and the percentage of CVPR papers that target efficiency?",55%,55,%,['schwartz2019'],is_blank,"For over 90% of the ML publications, only focus on model accuracy improvements at the expense of efficiency [109].",
,"True or False: The AI Act makes energy consumption data from providers publicly available to NGOs, analysts, and the general public.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,What is the projected maximum batch size (in samples) for fine-tuning a Mixtral model with a projected GPU capacity of 100?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,What was the approximate speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs?,The approximate speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs was 2x.,2,is_blank,['samsi2024'],is_blank,The speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs was 2x. (samsi2024),
,"What is the estimated total operational water consumption for training GPT-3 in Microsoft's U.S. data centers, in million liters?",The estimated total operational water consumption for training GPT-3 in Microsoft's U.S. data centers is 5.439 million liters.,5439000,million liters,['li2025b'],is_blank,"The supporting materials can be found in the context under 'li2025b'. Specifically, the answer is calculated using equation (1) and the values for PUE, CI, and water consumption during manufacturing are obtained from Luccioni et al. (2023).","The total power consumption during model training, development, and inference is estimated and then used to estimate the total carbon emissions and water consumption during each stage. The CO<sub>2</sub> emissions are calculated using equation (2) from the paper Luccioni et al. (2023). The water consumption during manufacturing is also amortized over the lifetime of the hardware. The total water consumption for GPT-3 training in Microsoft's U.S. data centers is then obtained by multiplying the CO<sub>2</sub> emissions and water consumption during manufacturing by the number of GPU hours used throughout model development and training."
,True or False: The authors propose that sustainability impact assessments (SIAs) should apply not just to high-risk AI but across all AI systems.,TRUE,1,is_blank,['luccioni2025a'],is_blank,"While debates over AI's role in climate change and sustainability have become increasingly polarized, both sides have tended to focus only on the direct impacts of this technology— positive and negative. But direct effects are not the whole story. As we show in the next section, the integration of AI into tools and systems reshapes social structures and influences human behavior, which ultimately has complex environmental consequences.",The authors suggest that indirect impacts of AI on the environment should be considered along with direct effects to make discussions about AI's environmental costs and benefits more complete. This implies that sustainability impact assessments (SIAs) should not just apply to high-risk AI but across all AI systems.
,"As of 2023, what was the water use effectiveness (WUE) for AWS data centers, in L/kWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,True or False: Local inference was emphasized as a sustainability measure because it reduces both network overhead and carbon footprint when deploying large language models.,True,1,is_blank,['khan2025'],is_blank,,
,True or False: Tracking the runtime of a training job is an important step for estimating compute cost in GPU-based or cloud environments.,Tracking the runtime of a training job is an important step for estimating compute cost in GPU-based or cloud environments.,1,is_blank,['patterson2021'],is_blank,Patterson2021: 'We believe it is straightforward for ML practitioners to calculate energy consumption. They already know hours to train and number of processors.',"The text states that knowing the hours to train (runtime) and the number of processors allows ML practitioners to calculate energy consumption, which implies that tracking the runtime is important for estimating compute cost."
,"For the LLaMA-65B model, what was the maximum performance improvement (latency reduction) achieved by enabling the automated resource utilization overlapping feature in the 2025 Chen et al. study?",The maximum performance improvement (latency reduction) achieved by enabling the automated resource utilization overlapping feature in the 2025 Chen et al. study for the LLaMA-65B model was 13.2%.,13.2,%,['chen2024'],is_blank,,
,How much does an elephant weigh?,The CO2 emissions in pounds from training a BERT base model for 12 hours using 1 P100 GPU,"33,544 lbs",lbs,['patterson2021'],is_blank,"hours per train steps = 12 hours / 100,000 = 0.00012 (Section 5.2 in [Vas17])\n$CO_2e = 1 * 979,000,000 * 0.00012 * 0.2855296 = 33,544 lbs (15.2 t)",
,"Which of the following five large NLP DNNs has the highest energy consumption: Meena, T5, GPT-3, GShard-600B, or Switch Transformer?",GPT-3,GPT-3,is_blank,['patterson2021'],is_blank,"The exact answer is not explicitly mentioned in the context, but it can be inferred from the paper 'patterson2021' which discusses techniques to reduce the computational cost and energy consumption of models. Among these techniques, distillation transfers the knowledge from large models into smaller, more computationally efficient models. GPT-3 is a large NLP DNN that can be considered as a starting point for such distillation.",
,How many days of CO₂ emissions from an average American life are equivalent to training BERT base?,The number of days of CO₂ emissions from an average American life equivalent to training BERT base is 14.4.,14.4,days,['strubell2019'],is_blank,"Training BERT base for 79 hours using 64 V100 GPUs emits 283.5 metric tons of CO₂, which is equivalent to the emissions from an average American life in 14.4 days according to Strubell et al.",
,True or False: The Transformer architecture eventuallly outperforms the Evolved Transformers architecture on the WMT'24 EN-DE BLUE task as the model sizes grow.,FALSE,0,is_blank,"['patterson2021', 'dodge2022', 'morrison2025', 'chen2024', 'khan2025', 'luccioni2025c', 'luccioni2023', 'shen2024', 'chung2025', 'xia2024', 'wu2021a', 'strubell2019', 'li2025a', 'kim2025', 'griggs2024', 'fernandez2025', 'samsi2024', 'zschache2025', 'schwartz2019', 'luccioni2024']",is_blank,,
,"What dataset of 5,842 labeled entries was used to test energy-efficient large language models in the financial domain?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,True or False: Eight T4 spot instances could be more cost-efficient than a DGX-2 node for distributed training.,True,1,is_blank,['erben2023'],is_blank,,
,True or False: The 2023 US Executive Order regarding AI mentioned the greenhouse gas emissions or energy usage of AI.,False,0,is_blank,['khan2025'],is_blank,The 2023 US Executive Order regarding AI is not mentioned in the context.,"The provided context does not contain any information about the 2023 US Executive Order regarding AI. Therefore, it cannot be determined whether or not it mentions greenhouse gas emissions or energy usage of AI."
,"True or False: Under Germany's 2023 Energy Efficiency Act, data centers must run on 100% renewable energy by January 1, 2027.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,"Out of a sample of 60 papers from top AI conferences, how many papers from ACL targeted both accuracy and efficiency?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,"According to recent estimates, what percentage of a model's total lifecycle energy use can inference account for?",Up to 90%,90,%,['jegham2025'],is_blank,\,
,True or False: The AI Act requires providers to report both training and inference energy consumption for general-purpose AI models.,False,0,is_blank,['ebert2024'],is_blank,,
,True or False: The AI Act currently requires providers to report energy use during the inference phase of AI models.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,True or False: New AI data centers often rely on air cooling due to high server power densities.,False,0,is_blank,['68'],is_blank,"Most of these training, fine-tuning and inference computations are conducted in data centers. However, the context does not specify that new AI data centers often rely on air cooling due to high server power densities.",The context discusses the computations being conducted in data centers but does not provide information about the cooling methods used specifically for new AI data centers.
,By what factor did platform-level caching improve the power efficiency of the inference workload for the cross-lingual Transformer language model described in Wu et al. (2021)?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,What is the estimated CO2 emissions in pounds from training a BERT base model for 79 hours using  64 V100 GPUs?,1438 lbs,1438,lbs,['strubell2019'],is_blank,,
,"According to a recent paper, what percentage of total compute demand does ML inference reportedly account for?",Up to 90%,90,percentage,['jegham2025'],is_blank,"According to recent estimates, what percentage of a model's total lifecycle energy use can inference account for?",
,How many U.S. household-years of electricity consumption is training a 6.1B-parameter language model equivalent to?,The training of a 6.1B-parameter language model is equivalent to 0.3 household-years of electricity consumption.,0.3,household-years,['luccioni2023'],is_blank,"For instance, a model trained on a single GPU consuming 300 W for 100 hours on a grid that emits 500 gCO2eq/kWh will emit 0.3 kW × 100 h × 500 g/kWh = 15000 g = 15 kg of CO2eq. The same model trained on a less carbon-intensive energy grid, emitting only 100 gCO2eq/kWh, will only emit 0.3 × 100 × 100 = 3000 g = 3 kg of CO2eq, i.e. five times less overall.",
,True or False: Egress costs in geo-distributed NLP experiments could account for more than 90% of the total cost per VM.,True,1,is_blank,['10-12'],is_blank,,
,"Given the total pre-training GPU hours and the number of GPUs used, estimate the total wall-clock time in days required to pre-train the JetMoE-8B model.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,"What is the term for the amount of water evaporated, transpired, or incorporated into products, and is defined as 'water withdrawal minus water discharge'?","The term for the amount of water evaporated, transpired, or incorporated into products is 'water consumption'.",Water consumption,is_blank,['amazon2023'],is_blank,"As of 2023, what was the water use effectiveness (WUE) for AWS data centers, in L/kWh?","The question asks about water consumption but does not provide an exact value or unit. The supporting materials quote is from a different context discussing WUE, which is related to water consumption."
,What was the observed range of inference energy per second for LLaMA-65B across GPU shard configurations?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,"When comparing small and large versions of Qwen models in zero-shot classification, how many times more energy did the 72B version consume than the 7B version?",The 72B version of Qwen models consumed approximately 8.72 times more energy than the 7B version in zero-shot classification.,8.720430108,,['zschache2025'],is_blank,"According to Zschache et al.'s study, when comparing small and large versions of Qwen models in zero-shot classification, the 72B version consumed approximately 8.72 times more energy than the 7B version.",
,By what percentage did Qwen's carbon emissions fall when applying quantization and local inference for sentiment classification?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
,How many widely used model architectures across different tasks were included in the latest iteration of the ML.ENERGY Benchmark?,The number of widely used model architectures across different tasks included in the latest iteration of the ML.ENERGY Benchmark is 40.,40,is_blank,['70'],is_blank,Table 1 Selection of large language models,"The table lists 40 different models, which are the ones included in the latest iteration of the ML.ENERGY Benchmark."
,"In the analysis of training a Llama-3.1 scale model, what was the estimated health cost, In USD, when training in Altoona, Iowa?",$2.51 million,2510000,USD,['han2024'],is_blank,"The estimated health cost when training a Llama-3.1 scale model in Altoona, Iowa was $2.51 million according to Han et al. (2024)",
