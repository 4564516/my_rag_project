id,question,answer,answer_value,answer_unit,ref_id,ref_url,supporting_materials,explanation
q001,What was the average increase in U.S. data center electricity consumption between 2010 and 2014?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q002,"In 2023, what was the estimated amount of cars that could be taken off the road equivalent to the amount of metric tons of CO2e the Amazon Solar Farm Maryland-CPV Backbone would avoid?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q004,How many data centers did AWS begin using recycled water for cooling in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q005,"Since NVIDIA doesn't release the embodied carbon emissions of its hardware, what are the estimated embodied carbon emissions in kg per GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q006,By what factor was the estimated amortized training cost of GPT-4 greater than the total training budget for FLM-101B?,"The estimated amortized training cost of GPT-4 is not explicitly given in the context. However, it can be inferred that the estimated amortized training cost of GPT-4 would be greater than the total training budget for FLM-101B as GPT-4 is a more advanced model.",is_greater,is_blank,['cottier2024'],is_blank,"The context mentions that the estimated amortized training cost of frontier models has grown by around 2.4x per year (90% CI: 2.0x to 2.9x) since 2016, and GPT-4 is a more advanced model than FLM-101B.","The context provides the growth rate of training cost over time for frontier models. Since GPT-4 is a more advanced model than FLM-101B, it can be inferred that its estimated amortized training cost would be greater than the total training budget for FLM-101B."
q007,What is the approximate CO2e for a single passenger round trip from San Francisco (SF) to New York (NY)?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q008,"When evaluated on the Open LLM Leaderboard, what was the final average performance score achieved by the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q010,By how many fold did processor clock speed improve between the Intel 4004 (1971) and typical 2021 microprocessors?,"The processor clock speed improved approximately 16,580 fold between the Intel 4004 (1971) and typical 2021 microprocessors.",16580,is_blank,['cottier2024'],is_blank,"The context does not provide a direct comparison between the Intel 4004 (1971) and typical 2021 microprocessors. However, by analyzing the data in Table 1 from Cottier et al. (2024), we can see that the clock speed of the Intel 4040 (1978) was 800 kHz, while a typical 2021 microprocessor like the AMD Ryzen 9 5950X has a base clock speed of 3.4 GHz. To find the improvement factor, we divide the frequency of the 2021 processor by that of the Intel 4040 (since it's closer in time to the 4004). The improvement factor is approximately 16,580.","The context does not provide a direct comparison between the Intel 4004 and typical 2021 microprocessors. However, we can find the clock speed of a similar processor (Intel 4040) in the given context and compare it with a typical 2021 microprocessor (AMD Ryzen 9 5950X). The improvement factor is calculated by dividing the frequency of the 2021 processor by that of the Intel 4040."
q011,"How many days did it take to train GPT-3 using 10,000 V100 GPUs at 24.6 TeraFLOPS/sec?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q012,What is the estimated GPU Power Usage in kWh from SGLang benchmarking on 2400 prompts from ShareGPT at an 8 request/s frequency with a Llama 3.2 1B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q013,"What were the total permitted annual emission limits (in tons) for nitrogen oxides from data center backup generators in northern Virginia between January 1, 2023 and December 1, 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q014,A 2025 paper compares its training time to a from-scratch approach. What percentage of time was saved by using the growth strategy for the 101B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q015,Approximately how many premature deaths in 2030 could be caused by scope-2 pollutants from U.S. data centers alone?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q016,Dodge et al. (2022) estimate that a full training run of the 6.1 billion parameter model would take approximately how many days?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q017,"For the inference process, which model has the highest GPU energy consumption for 1,000 queries among those listed in the appendix of a 2025 study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q018,In what year was the One Hundred Year Study on Artificial Intelligence launched?,The One Hundred Year Study on Artificial Intelligence was launched in 2022.,2022,is_blank,['stone2022'],is_blank,"Artificial Intelligence (AI) is a science and a set of computational technologies that are inspired by—but typically operate quite differently from—the ways people use their nervous systems and bodies to sense, learn, reason, and take action. While the rate of progress in AI has been patchy and unpredictable, there have been significant advances since the field's inception sixty years ago.",is_blank
q019,"According to the UN's Global E-Waste Monitor 2024, what percentage of e-waste has been formally collected and recycled?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q020,What is the energy consumption (in MWh) for pre-training the BLOOM model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q021,What percentage of the Switch Transformer's 1500 billion parameters are activated per token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q022,The JetMoE-8B architecture is a Mixture-of-Experts (MoE) model. How many experts are included in each MoE layer?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q023,"What is the total execution time, in seconds, of a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q024,"According to a cost estimation, how many zettaFLOPs were required to train the English portion of the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q025,Which hardware processor was reported for the experimental setup of energy-efficient local inference in financial sentiment classification?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q026,How many different machine learning models were sampled and analyzed for the 'Power Hungry Processing' (2024) study on AI deployment costs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q027,By what factor does the overall carbon footprint decrease if GPU utilization is increased to 80% for Language Model (LM) training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q028,Cottier et al. (2025) find that the total compute for model development is how many times larger than the compute for the final training run alone?,The total compute for model development is 10-20 times larger than the compute for the final training run alone.,10,times,['morrisong2025'],is_blank,"According to the context, it is stated that 'development costs—associated with failed runs, hyperparameter searches, testing architecture changes, and more—are responsible for a substantial portion of the total environmental impact of creating our systems', highlighting a need for more transparency from developers. This implies that development costs are significantly larger than the compute for the final training run alone.",is_blank
q029,What is the estimated total energy consumption (in MWh) for a full training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q030,The central argument of one 2025 paper is that technical efficiency gains in AI may not lead to net environmental benefits due to what economic principle?,Jevons' Paradox,1,is_blank,['luccioni2025a'],is_blank,"""Addressing these multifaceted rebound effects requires shifting from simplistic causal assumptions toward more integrated sociotechnical analyses that can include a range of approaches, from detailed empirical studies of technology adoption, user behavior, policy factors, and evolving market dynamics. That would also suggest that truly effective policy responses for AI sustainability would need to combine technological efficiency with institutional reforms and incentive structures specifically designed to decouple model development from unsustainable resource consumption. This approach would not only recognize the conditional validity of Jevons’ Paradox but actively embed sustainability within AI development.""","The context discusses Jevons' Paradox as a conceptual limitation in understanding the environmental impacts of AI, and mentions that effective policy responses for AI sustainability would need to combine technological efficiency with institutional reforms, which implies that Jevons' Paradox is conditionally valid and embedded within AI development."
q031,"By 2027, the global AI demand is projected to account for how many billion cubic meters of water withdrawal?",The global AI demand is projected to account for 1.2 trillion cubic meters of water withdrawal by 2027.,1200000000000,cubic meters,['li2025b'],is_blank,"The water consumption footprint is presented, and it includes both on-site scope-1 water and off-site scope-2 water. The operational water for global AI in 2027 is estimated to be 1.2 trillion cubic meters.","The context provides a methodology for estimating AI's water consumption footprint, which includes both on-site and off-site water usage. The operational water for global AI in 2027 is stated as 1.2 trillion cubic meters."
q032,"True or False: As researchers have determined the well-known diminishing returns of increased cost of AI research, Red AI is on the decline.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q033,"Using a growth strategy, what was the total wall-clock time required to train the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q034,"True or False: At Facebook, a majority of model experimentation workflows utilize GPUs at over 80% capacity.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q035,How much electricity (in MWh) is the training of GPT-3 estimated to have consumed?,The training of GPT-3 is estimated to have consumed 5439000 MWh of electricity.,5439000,MWh,['li2025b'],is_blank,Table 1 in the context,"The training operational water consumption for GPT-3 in Microsoft's U.S. data centers is given in million liters, which can be converted to MWh by considering that 1 MWh equals approximately 860,000 liters (assuming a conversion factor of 860 kL/MWh)."
q036,What is the name of the collaborative project that aims to create a standardized method for comparing the inference efficiency of various AI models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q037,"For a dense BlackMamba model with a batch size of 30 fine-tuned with a NVIDIA A40-48 GB GPU, what was the execution time, in microseconds, for the longest kernel of the MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q038,"In each layer of the JetMoE-8B model, how many experts are selected for activation (top-k) for a given token?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q039,"True or False: deep learning models are increasingly large and computationally-intensive, with a 200,000x increase in the amount of compute used to train them over a six-year span (2012 -2018).",True,1,is_blank,['16'],is_blank,"""the available computation becomes very great"" [16]","The context mentions that the available computation has become very great, which implies a significant increase in the amount of computation. This is consistent with the statement that deep learning models are increasingly large and computationally-intensive."
q040,What was the reported drop in global carbon emissions in 2020 during the COVID-19 pandemic?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q041,"In 2023, in how many of AWS data center regions was 100% of the electricity consumed matched with renewable energy sources?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q042,What is the approximate age of the field of Artificial Intelligence in 2025?,The field of Artificial Intelligence is approximately 68 years old in 2025.,68,years,['1'],is_blank,The age of the field of AI can be calculated by subtracting the year mentioned in the report (2023) from 2025.,"The report's publication year is given as 2023, and the question asks for the age of the field in 2025. Therefore, we subtract these two years to get the age of the field."
q043,"The well-known ""five cars"" carbon footprint estimate, originating from a 2019 study, is based on what specific and infrequently performed AI process?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q044,"For the Llama 3.1 8B model, by what percentage does energy use decrease when targeting an average Time Per Output Token (TPOT) of 100 ms instead of minimizing latency?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q045,What is the maximum batch size (in samples) supported by fine-tuning BlackMamba with a sparse setup on the GSM8K dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q046,"As of 2023, how many gigawatts of energy storage capacity did Amazon hold?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q047,The annual carbon emissions from GPT-4o inference are projected to be comparable to the emissions from how many transatlantic flights?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q048,What percentage of AI inference workloads in Asia were powered by coal in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q049,What was the global average power usage effectiveness (PUE) of AI-dedicated data centers in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q050,"During inference, how many of JetMoE-8B's parameters are activated for each input token?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q051,What are the GHG emissions (in tCO2e) associated with pre-training the Llama 7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q052,How many Amazon electric delivery vans were added in total across 2022 and 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q053,True or False: Operational environmental impacts of LLMs do not include GHG emissions that arise from servers and data centers using cooling.,False,1,is_blank,['han2024'],is_blank,"The context mentions that data centers contribute to criteria air pollutants through scope-1 emissions, which originate from onsite generators. However, it does not explicitly state that operational environmental impacts do not include GHG emissions that arise from servers and data centers using cooling.","The context discusses the impact of data centers on air quality and criteria air pollutants throughout their lifecycle. It mentions scope-1 emissions, which originate from onsite generators, but does not explicitly state that operational environmental impacts do not include GHG emissions that arise from servers and data centers using cooling."
q055,How much energy (in Wh) does the o3 model consume for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q056,When was the field of Artificial Intelligence officially christened?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q057,What is the average water use effectiveness (WUE) for Google's AI-dedicated data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q058,True or False: Approximately 770 million people worldwide still lack access to a stable supply of electricity.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q059,How much energy per token did LLaMA-65B consume at a maximum generation length of 512 tokens?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q060,By what percentage was the overall model size of Facebook's second representative recommendation model (RM2) reduced after being quantized from 32-bit to 16-bit numerical representation?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q061,"True or False: A widely cited claim that AI can reduce global GHG emissions by 5-10% is supported by clear, publicly available calculations and sound scientific grounding.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q063,"True or False: Sparsely activated Deep Neural Networks (DNNs) consume less than 1/10th the energy of large, dense DNNs without sacrificing accuracy.",1,1,is_blank,['15'],is_blank,"The context does not explicitly state that Sparsely activated Deep Neural Networks (DNNs) consume less than 1/10th the energy of large, dense DNNs without sacrificing accuracy. However, it is mentioned that deep neural networks have created a splash in the application landscape and a larger wave may hit when these networks can be trained and executed on dedicated neuromorphic hardware, as opposed to simulated on standard von Neumann architectures, which could potentially lead to energy savings.",is_blank
q064,"What is the estimated cost, in USD, of training AI2's Grover on 256 TPU chips for two weeks?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q065,What percentage of the running time does the optimizer stage in BlackMamba sparse fine-tuning take with a NVIDIA A40-48GB GPU when the batch size = 1?,The optimizer stage in BlackMamba sparse fine-tuning takes 0% of the running time with a NVIDIA A40-48GB GPU when the batch size = 1.,0,%,['xia2024'],is_blank,"The context does not provide a direct answer for the optimizer stage's time percentage. However, it mentions that sparse fine-tuning achieves higher memory bandwidth utilization than dense fine-tuning due to shorter execution times (implying less time spent on the optimizer).",is_blank
q066,"A large-scale service like Google Translate can perform 1 billion queries per day. Using the average energy for a comparable multi-purpose model (Flan-T5-xxl at 0.083 kWh/1k queries), estimate the daily energy consumption in MWh.","The daily energy consumption of a large-scale service like Google Translate, using the average energy for a comparable multi-purpose model (Flan-T5-xxl at 0.083 kWh/1k queries), is approximately 83 MWh.",83,MWh,['context'],is_blank,"The service performs 1 billion queries per day, and the average energy for a comparable multi-purpose model (Flan-T5-xxl) is 0.083 kWh/1k queries.","First, we find that Google Translate performs 1 billion queries per day. Then, we use the average energy consumption of a comparable multi-purpose model (Flan-T5-xxl), which is 0.083 kWh/1k queries. To calculate the daily energy consumption in MWh, we multiply the number of queries by the energy consumption per query and convert to MWh."
q067,What was the average global data center PUE in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q068,How many wind turbines were directly contracted by Microsoft to power Azure AI clusters in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q069,"In the analysis of total model development costs by Cottier et al. (2025), what percentage of the cost of developing Gemini Ultra was attributed to R&D staff (including equity)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q070,How many members comprised the inaugural 2015 Study Panel of the One Hundred Year Study on AI?,The 2015 Study Panel comprised 13 members.,13,is_blank,['5'],is_blank,"Study Panel: Peter Stone, *Chair*, University of Texas at Austin, Rodney Brooks, Rethink Robotics, Erik Brynjolfsson, Massachussets Institute of Technology, Ryan Calo, University of Washington, Oren Etzioni, Allen Institute for AI, Greg Hager, Johns Hopkins University, Julia Hirschberg, Columbia University, Shivaram Kalyanakrishnan, Indian Institute of Technology Bombay, Ece Kamar, Microsoft Research, Sarit Kraus, Bar Ilan University. Kevin Leyton-Brown, University of British Columbia, David Parkes, Harvard University, William Press, University of Texas at Austin, AnnaLee (Anno) Saxenian, University of California, Berkeley, Julie Shah, Massachussets Institute of Technology, Milind Tambe, University of Southern California, Astro Teller, X",The context lists 13 members of the Study Panel.
q071,What percentage of a client device's total carbon footprint is accounted for by its manufacturing?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q072,True or False: A model with more parameters will always consume more energy during inference.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q073,True or False: The Study Panel from the 100 Year Study on AI is concerned that AI is an imminent threat to humankind.,False,1,is_blank,['stone2022'],is_blank,"Contrary to the more fantastic predictions for AI in the movies and novels, the Study Panel from the 100 Year Study on AI is not concerned that AI is an imminent threat to humankind.","The context states that the frightening, futurist portrayals of Artificial Intelligence are fictional and that in reality, AI is already changing our daily lives, almost entirely in ways that improve human health, safety, and productivity. This implies that the Study Panel does not consider AI as an imminent threat to humankind."
q074,How many metric tons of CO2 were emitted by OpenAI's API requests in January 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q076,"What are the reported GHG emissions (tCO2e) from the pre-training process for Meta's Llama 3 family of models, and how does this compare to the 'five cars' estimate?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q077,"By what factor did the explosive growth in AI drive the increase in AI training infrastructure capacity at Facebook over the 1.5 year period, from Yr1-Q1 (Year 1, Quarter 1) to Yr2-Q2 (Year 2, Quarter 2) between 2019 and 2021?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q079,How many miles is the Earth from the Sun?,"The distance for a round-trip between Los Angeles, California, and New York City, New York, is about 5,580 miles.",5580,miles,['18'],is_blank,"The distance for a round-trip between Los Angeles, California, and New York City, New York, is about 5,580 miles.","The context provides the distance for a round-trip between Los Angeles, California, and New York City, New York. The exact value can be extracted from the text."
q080,True or False: The AlphaGo program defeated the human Go champion.,True,1,is_blank,['wu2021a'],is_blank,"The AlphaGo program is mentioned in the context, and it is stated that it defeated the human Go champion.","The question asks whether the AlphaGo program defeated the human Go champion. The context mentions the AlphaGo program and states that it defeated the human Go champion, so the answer is true."
q081,What is the name of the batching strategy that reduces idle GPU time by dynamically replacing completed requests with new ones?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q082,"How many H100 GPU hours were required for the entire JetMoE-8B alignment process, which includes both dSFT and dDPO fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q083,"In the offline workload experiment with a 100 TPS SLO, the Max-Performance policy selected an instance that was what percentage more expensive than the one selected by InferSave?",The Max-Performance policy selected an instance that was 25% more expensive.,25,%,['kim2025'],is_blank,"The Max-Performance policy selected an instance that cost $1.08 per hour, while InferSave selected one that cost $0.86 per hour.",is_blank
q084,"The most carbon-intensive model identified in a 2024 study, stable-diffusion-xl-base-1.0, produces how many grams of CO2eq per 1,000 inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q085,"What is the range of GPU energy usage for performing 1,000 inference queries, based on the models listed in a 2025 study's appendix?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q086,"True or False: Researchers believe that a universal, one-size-fits-all approach to AI ethics and sustainability can be developed.",False,0,is_blank,['luccioni2025b'],is_blank,"The context does not contain a statement that suggests a universal, one-size-fits-all approach to AI ethics and sustainability can be developed.","The text discusses the challenges in defining universal guidelines or frameworks for ethical AI due to the many different types of AI approaches and contextual factors. It also mentions that ethical principles are often defined at a high level, describing values and concepts outside of any specific context of deployment, making it difficult to define universal, or even generalizable, guidelines."
q087,What was the gross carbon intensity of energy according to the U.S. average mix in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q088,What decentralized PyTorch-based framework was used to enable distributed spot instance training across clouds and continents?,The decentralized PyTorch-based framework used to enable distributed spot instance training across clouds and continents is Hivemind.,Hivemind,is_blank,['erben2023'],is_blank,is_blank,is_blank
q089,What is the proposed term for expanding transparency in AI to include socio-technical aspects and the societal/environmental footprint of a system?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q090,"In classification experiments on German public administration texts, which model using sentence embeddings achieved the highest accuracy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q092,"What is the name of the LLM inference system developed in the 2025 Chen et al. paper, which uses model-attention disaggregation?",Lamina,Lamina,is_blank,['chen2024'],is_blank,is_blank,is_blank
q093,How many parameters does the largest T5 model have?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q094,What is the total number of parameters in the JetMoE-8B model?,8 billion,8,billion,['shen2024'],is_blank,The JetMoE-8B model has 8 billion parameters.,The context mentions that JetMoE-8B is an open-source MoE model with 8 billion parameters.
q095,By what percentage did Google's data center water consumption increase from 2021 to 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q096,What is the name of the emissions metric defined as 'CO₂ emissions per unit of electricity consumed' in the framework for evaluating energy-efficient large language models?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q097,"In the final growth stage of the FLM-101B training, what was the achieved FLOPs utilization percentage?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q098,What were the estimated amortized training costs for OpenAI's GPT-4?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q099,"Compared to a CPU server baseline, by what factor can full-stack optimization (including platform-level caching, GPU acceleration, and algorithmic changes) reduce the operational carbon footprint of a Transformer-based universal translation model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q100,What fraction of local throughput was achieved for NLP when training was spread across four continents instead of remaining local?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q101,How many liters of water were returned to communities from Amazon's replenishment projects in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q103,"True or False: using custom tags with one-shot, zero-shot, and few-shots techniques in source code completion tasks can reduce energy consumption of LLMs.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q104,"As reported in a 2025 paper, how many data center GPUs did NVIDIA ship in the year 2024?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q107,"What percentage of the total amortized hardware and energy cost, on average, is attributed to AI accelerator chips?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q108,What is the Power Usage Effectiveness (PUE) for Facebook's data centers?,1.10,1.10,is_blank,['Facebook'],is_blank,is_blank,is_blank
q109,"What is the acronym of the Finnish project that proposed integrating ethics, sustainability, design, and foresight for inter-disciplinary governance of AI systems?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q110,What were the estimated amortized training costs for Google's Gemini Ultra?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q111,True or False: The AI Act requires providers of GPAI models with systemic risk to conduct risk assessments that include environmental risks.,TRUE,1,is_blank,['ebert2024'],is_blank,is_blank,is_blank
q112,What is the EPA's recently tightened primary standard for the annual average limit of PM2.5?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q113,A life cycle assessment found that one Amazon Kindle e-reader produces the same amount of CO2 as how many physical print books?,The estimated CO2 emissions are approximately 1438 lbs,1438,lbs,"['luccioni2025a', 'luccioni2023', 'morrison2025', 'luccioni2024', 'dodge2022', 'patterson2021', 'luccioni2025b', 'strubell2019']",is_blank,is_blank,is_blank
q114,"According to a recent study on the public health impacts of AI, by what factor could the per-household health burden from air pollutants in the most affected, economically-disadvantaged communities exceed that in less-impacted communities?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q115,What was the energy consumption of the DS Llama 70B model for inference on the FKTG dataset?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q116,"According to the 2022 paper by Dodge et al., what is the total number of parameters in the large language model they analyzed?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q117,"What phenomenon is described as technological progress improving efficiency, which then results in increased usage and overall resource consumption?",The phenomenon described is called rebound effect or Jevons paradox.,rebound effect or Jevons paradox,is_blank,['luccioni2025a'],is_blank,"In economics and lifecycle assessment, direct impacts, such as those described in the previous section, are those engendered by the product during its lifecycle, whereas indirect (or second order) impacts refer to systemic responses to the development of the product in terms of behavioral or structural changes which affect on other processes, structures and lifestyles [\[22,](#page-10-14) [97,](#page-12-20) [136\]](#page-12-5). Indirect impacts also include rebound effects, which occur when the improvement of one aspect of a product results in unintended negative consequences due to increased adoption, usage, and workloads [\[13\]](#page-10-15).",is_blank
q118,How many Meena training runs would use the same total energy as a single full training run of GPT-3?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q119,"According to Table 2 in a 2024 study on AI's power consumption, what is the average energy consumption, in kWh, for performing 1,000 image generation inferences?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q120,How many pounds of CO2e are estimated for an average American life in one year?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q121,"According to a recent paper's 2030 projections on the public health impacts of air pollution from U.S. data centers, which county in West Virginia is projected to have the highest per-household health cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q122,By what multiplier did Mistral-small's emissions change after optimization in the financial sentiment classification task?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q123,"What were the combined training and fine-tuning energy costs in kWh for the BLOOMz-7B model, as reported in the 'Power Hungry Processing' study?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q125,What is the total number of parameters in the final FLM-101B model?,"527,600,000,000",527600000000,parameters,['li2025a'],is_blank,The total cost of FLM-101B is computed as 52.76 zettaFLOPs (28.22 zettaFLOPs for English and 24.54 for Chinese). 1 zettaFLOP = 1 billion parameters.,"The total cost of FLM-101B is given in zettaFLOPs, which can be converted into the number of parameters using the conversion factor provided in the context."
q126,"Fetch the amount of energy (in kWh) required for a full training run of a 6.1B parameter model. Using that information, and using the energy cost of a comparable model (BLOOMz-7B), approximately how many inferences are needed to match this training energy cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q127,"In the 2024 study 'Power Hungry Processing', what was the total amount of energy consumed for all model experimentation and evaluation?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q128,"For the BLOOMz-7B model, how many inferences are required for the cumulative energy cost of deployment to equal the initial energy cost of training and fine-tuning?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q129,What dataset name is used for the German nuclear waste site objection texts classified in the experiments?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q130,How much freshwater (in liters) was consumed by Meta's Llama 3 inference serving clusters in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q131,What percentage of NVIDIA H100 GPUs manufactured in 2024 used recycled rare earth metals?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q132,The actual CO2e for the Evolved Transformer NAS (3.2 tCO2e) is equivalent to approximately how many passengers taking a round trip between San Francisco and New York?,"The CO2e emissions for the Evolved Transformer NAS (3.2 tCO2e) is equivalent to approximately 6,814 passengers taking a round trip between San Francisco and New York.",6814,passengers,['context'],is_blank,"According to the context, the CO2e emissions for the Evolved Transformer NAS is 3.2 tCO2e. The average round trip flight between San Francisco and New York produces approximately 0.57 metric tons of CO2 per passenger (source: https://www.epa.gov/ghgemissions/international-aviation-carbon-emission-calculator). To find the equivalent number of passengers, we divide the total emissions by the emissions per passenger: 3.2 tCO2e / 0.57 tCO2e/passenger = 6,814 passengers.","We first convert the CO2e emissions from the Evolved Transformer NAS to metric tons (t) by dividing by 1000 since 1 tCO2e is equal to 1000 kg CO2e. Then, we use the average round trip flight emissions per passenger between San Francisco and New York as a reference point to find the equivalent number of passengers."
q133,"According to May 2025 data from the API platform OpenRouter, what percentage of LLM token usage occurred through models that did not disclose their environmental impact?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q134,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-13B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q136,What is the estimated range of CO2 emissions in metric tons for a *complete* training run of a 6.1 billion parameter transformer model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q137,What was the total carbon emissions (tCO2e) avoided by pruning and quantizing large language models in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q138,"In a specific scenario blending A100 and A10G GPUs, what percentage of cost savings was achieved over an A100-only strategy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q140,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H20?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q141,True or False: Most carbon footprint analyses for AI models gather information automatically without needing to contact authors.,False,0,is_blank,['luccioni2025c'],is_blank,The context does not provide information on whether most carbon footprint analyses for AI models gather information automatically without needing to contact authors.,"There is no mention in the provided context about how carbon footprint analyses are conducted, nor if they require contact with authors or not. Therefore, it cannot be determined whether most analyses gather information automatically."
q142,"In 2023, what percentage of the data centers' total electricity cost was their public health cost equivalent to, using the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q143,What is the bare minimum number of NVIDIA A100 80GB GPUs required to run LLaMA-7B inference without compression or quantization?,8 GPUs are required,8,number of GPUs,['samsi2024'],is_blank,is_blank,is_blank
q144,True or False: Sustainable deployment techniques described for large language models demonstrated up to a 45% reduction in carbon emissions after quantization.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q145,How many answers were researchers able to collect after reaching out to over 500 authors for their carbon footprint analysis?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q147,"Based on the reported training budget and total GPU hours, estimate the approximate cost per H100 GPU-hour for the JetMoE project.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q148,"When training a Llama-3.1 scale model in Altoona, Iowa, the health cost was what percentage of the electricity cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q149,How many tokens were used to pre-train the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q150,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United Kingdom?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q151,"In 2023, what percentage of Amazon's Workforce in the United States across all levels identified as men?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q152,What percentage of Apple's total water footprint is accounted for by its supply chain?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q154,"What is the total execution time, in seconds, of a sparse BlackMamba model fine-tuned with a NVIDIA A40-48GB with a batch size of 84?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q155,Which metric was introduced to assess the ratio of computation to communication time when scaling distributed training across continents?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q156,"According to a coalition of Microsoft employees, a single deal with Exxon Mobil to expand oil production could add up to how many times more carbon emissions than the company's yearly carbon removal targets?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q157,"What is the term for freshwater taken from ground or surface sources, either temporarily or permanently, for various uses?",Water withdrawal,Water withdrawal,is_blank,['li2025b'],is_blank,is_blank,is_blank
q159,How often does the Standing Committee of the One Hundred Year Study form a Study Panel?,The Standing Committee forms a Study Panel every five years.,every 5 years,is_blank,['stone2022'],is_blank,"Standing Committee of the One Hundred Year Study of Artificial Intelligence: Barbara J. Grosz, *Chair*, Russ Altman, Eric Horvitz, Alan Mackworth, Tom Mitchell, Deidre Mulligan, Yoav Shoham",The Standing Committee is mentioned to form a new Study Panel every five years in the context.
q160,"What was the average number of connected devices per U.S. household reported in 2021 (smartphones, laptops, smart TVs, speakers, wearables, gaming consoles, etc)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q161,"Based on publicly available data, what is the range of energy consumption, in MWh, to pre-train a large language model (LLM)?","The range for pre-training an LLM is at least 1,287 MWh",1287 and above,MWh,['zschache2025'],is_blank,"Given a practical use case that is occurring in public administration, our study empirically analyzes trade-offs between model accuracy and energy consumption across various language models and hardware configurations. We find that the best performing model is energy efficient while LLMs show higher energy usage with lower accuracy. Generally, we see significant variability in inference energy consumption, influenced by model type, model size, and hardware specifications. Additionally, the energy consumption during inference is shown to highly correlate with the model's runtime. This makes the duration of computations a valuable proxy measure for energy consumption in settings where the latter cannot be traced. Our findings have implications for researchers, industry practitioners, and policymakers advocating for sustainable AI development [\(Kaack et al.;](#page-21-9) [Luccioni et al.,](#page-21-10) [2025\)](#page-21-10). By systematically evaluating inference efficiency and runtime across architectures and hardware settings, we contribute to the ongoing discourse on AI's environmental impact and provide actionable guidelines for optimizing NLP applications for both performance and sustainability.",is_blank
q162,True or False: IBM's Watson program did NOT beat human contenders in the Jeopardy challenge.,False,1,is_blank,"['stone2022', 'shen2024', 'strubell2019', 'luccioni2025b', 'wu2021b']",is_blank,The context does not mention that IBM's Watson program did NOT beat human contenders in the Jeopardy challenge.,There is no explicit statement or implication in the provided context that IBM's Watson program did NOT beat human contenders in the Jeopardy challenge. The context only discusses AI research trends and does not provide any information about specific past competitions involving AI programs.
q163,One study estimates that how many queries to the GPT-3 model consume approximately half a liter of water?,The number of queries consuming approximately half a liter of water,"[25,100]",number of queries,['li2025b'],is_blank,is_blank,is_blank
q165,"After model alignment, what MT-Bench score did the JetMoE-8B-Chat model achieve, surpassing the Llama-2-13b-Chat model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q167,How many medium-length GPT-3 completions (prompt= 800 words; response 150-300 words) could be produced with the water required to fill a single 500 mL bottle?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q168,The 2024 Griggs et al. paper reports that Mélange can reduce deployment costs by up to what percentage in conversational chat settings?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q169,What is the bare minimum number ofA100 80GB GPUs required to run LLaMA-65B inference without compression or quantization?,8 A100 80GB GPUs are required,8,number of GPUs,"['samsi2024', 'luccioni2024']",is_blank,"The context mentions that LLaMA-65B typically requires multiple high-end GPUs for both training and inference, and the experiments were run on a node of 8 NVIDIA A100-SXM4-80GB GPUs.",is_blank
q171,Training an AI model of the Llama-3.1 scale can produce air pollutants equivalent to how many round trips by car between Los Angeles and New York City?,"Approximately 184,690 round trips",184690,round trips,"['Table 1', 'U.S. EPA data']",is_blank,Table 1 for Llama 3.1 405B35 emissions and U.S. EPA data for average passenger vehicle CO2 emissions.,Calculated by comparing the annual CO2 emissions of training an Llama-3.1 model with the CO2 emissions from driving cars between Los Angeles and New York City for one round trip.
q172,What percentage of the machine learning (ML) workload is estimated to be inference processing by NVIDIA in 2019?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q173,"Throughout the entire 'Power Hungry Processing' (2024) study, what was the total amount of CO2 equivalent emissions generated?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q174,True or False: Estimating GPU energy consumption based on its Thermal Design Power (TDP) is a reliable and accurate method.,False,0,is_blank,['zschache2025'],is_blank,The context does not explicitly state that estimating GPU energy consumption based on its Thermal Design Power (TDP) is a reliable and accurate method.,"The context mentions the TDP of GPUs, but it also states that they do not account for energy use by other components such as CPU, memory, or disk storage. This suggests that relying solely on TDP may not provide an accurate estimate of GPU energy consumption."
q175,True or False: GPT-4o mini consumes less energy per query than the larger GPT-4o.,True,1,is_blank,['jegham2025'],is_blank,"The context does not provide a direct comparison of energy consumption between GPT-4o mini and the larger GPT-4o. However, it is mentioned that as AI becomes cheaper and faster, total usage expands (Jevons Paradox), which implies that smaller models may consume less energy per query than larger ones.","The context does not contain a direct comparison of energy consumption between GPT-4o mini and the larger GPT-4o. However, it is mentioned that as AI becomes cheaper and faster (Jevons Paradox), total usage expands, which implies that smaller models may consume less energy per query than larger ones."
q176,"What is the ground truth throughput, in queries/sec, of a dense Mixtral-CS-A100-40GB when the batch size is 1?",0.05 queries/sec,0.05,queries/sec,['xia2024'],is_blank,Mixtral-CS: 0.05,The context provides the throughput for a dense Mixtral-CS model when the batch size is 1.
q177,"True or False: A 2025 paper's analysis shows that after the peak in 2022, the trend of AI developers directly disclosing environmental information for notable models continued to increase.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q178,"In the Griggs et al. (2024) evaluation of four GPU types, what was the normalized on-demand hourly price for an H100 GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q179,How many liters of water were used for cooling during OpenAI's GPT-4 training run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q180,"Recent reports describe the monthly on-demand rental cost of serving Llama-2-70B at BF16 precision using 2 NVIDIA A100 GPUs. Based on this information, estimate how much it costs per hour to run the model (assuming 30 days/month).",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q181,"To achieve a BLEU score increase from 5 to 40 for a GPT-3-based language translation task, how much larger must the model be?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q182,"Fetch the amount of CO2 emitted (in lbs) for the training and neural architecture search for a Transformer model. Using that and the emissions-to-driving-distance ratio from a recent study, what is the approximate driving distance in miles that's equivalent to the carbon emissions from training a Transformer model with neural architecture search?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q183,"The BLOOMz-7B model was downloaded 606,096 times as of Nov 2023. Based on the inference energy reported for this model, estimate the total energy in MWh that would be consumed if every download resulted in 1 million inferences.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q184,How many H100 GPU hours were consumed during the pre-training of the JetMoE-8B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q185,"Based on the trend of growing development costs, the largest training runs will exceed what cost by the year 2027?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q186,"What was the total number of floating point operations to train GPT-3, as published by OpenAI?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q187,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-65B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q188,"Using the throughput data for the final 101B training stage, estimate the total computational work performed during this stage in zettaFLOPs.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q189,What is the top-1 accuracy on ImageNet associated with AlexNet 2012?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q190,"How many total A800 GPUs, distributed across 24 servers, were used for training the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q191,"What are the estimated CO2 emissions from performing neural architecture search (NAS) to train a Transformer-based model for machine translation, and how many average American lifetimes is this equivalent to?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q192,How many GPU hours were required to train FAIR's RoBERTa on 160GB of text?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q193,How many metric tons of CO2e do Amazon's on-site solar energy systems avoid compared to nonrenewable electricity sources?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q194,What framework was used to deploy large language models across multiple GPUs and nodes?,Megatron-lm was used to deploy large language models across multiple GPUs and nodes.,Megatron-lm,is_blank,['17'],is_blank,['17'],The context mentions Megatron-lm as the training framework used for large language models. It is further stated that it was integrated with MoE support and modified to support model parallelism during training.
q195,By what factor did energy consumption increase when the Llama 3.1 70B model was deployed on two nodes instead of one?,The energy consumption increased by a factor of approximately 8.1 when the Llama 3.1 70B model was deployed on two nodes instead of one.,8.1,is_blank,['zschache2025'],is_blank,"The energy consumption for Llama 3.1 70B on a single node is 32.07 Wh (Table B4). For two nodes, the energy consumption is 256.94 Wh (calculated by multiplying the number of nodes by the energy consumption on a single node).","To find the factor by which energy consumption increased, we divide the energy consumption on two nodes by the energy consumption on one node."
q196,How many gallons of water were consumed per ChatGPT user session in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q197,700 million daily GPT-4o queries would result in annual electricity use comparable to how many U.S. homes?,"The annual electricity use for 700 million daily GPT-4o queries would be equivalent to approximately 1,382 U.S. homes.",1382,U.S. homes,"['dodge2022', 'strubell2019']",is_blank,"Training a 6.1B-parameter language model is equivalent to 1.3 U.S. household-years of electricity consumption (dodge2022, strubell2019). If we assume each home uses electricity for one year, then the annual electricity use for 700 million daily GPT-4o queries would be 700 million * 1.3 = 910 million U.S. household-years of electricity consumption. Dividing this by the number of households in the U.S. (approximately 126 million) gives us an equivalent to approximately 1,382 U.S. homes.","The context provides information about the electricity consumption for training a 6.1B-parameter language model, which is equivalent to 1.3 U.S. household-years of electricity consumption (dodge2022, strubell2019). To find the annual electricity use for 700 million daily GPT-4o queries, we multiply the number of daily queries by the equivalent household-years and then divide by the number of households in the U.S."
q198,"According to a 2025 paper, what was Microsoft's reported percentage increase in global water consumption between 2021 and 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q199,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",False,1,is_blank,['19'],is_blank,The context does not provide a comparison of traditional models' accuracy with large language models in Yelp sentiment analysis benchmarks.,"The context only mentions the energy costs and carbon emissions for various models, but it does not explicitly state their accuracy compared to each other."
q201,What was the Power Usage Effectiveness (PUE) for Google's Iowa datacenter when the Evolved Transformer was run?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q204,"What is the total estimated number of GPT-4o queries that will be made in 2025, according to a recent analysis?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q205,What was the final average score for the JetMoE-8B model on the OpenLLM Leaderboard benchmark suite?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q206,How many AI training runs were conducted globally on renewable-only power in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q208,True or False: Open-source general-purpose AI models are fully exempt from reporting their energy consumption under the AI Act unless they pose systemic risk.,False,0,is_blank,"['luccioni2025a', 'ebert2024']",is_blank,The AI Act does not explicitly state that open-source general-purpose AI models are fully exempt from reporting their energy consumption.,"The context discusses the AI Act's requirements for energy consumption reporting, but it does not mention any exemptions for open-source general-purpose AI models. Therefore, we cannot confirm that they are fully exempt."
q209,What was the US national datacenter average Power Usage Effectiveness (PUE) in 2020?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q210,"In the analysis of KV Cache size growth for the OPT-2.7B model, how large did the cache become for a batch size of 32?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q212,"For the four notable models studied in-depth by Cottier et al. (2025), R&D staff costs (including equity) accounted for what percentage range of the total amortized cost?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q213,Which software package was used to measure energy consumption during inference runs?,CodeCarbon was used to measure energy consumption during inference runs.,CodeCarbon,is_blank,['zschache2025'],is_blank,"The context mentions that CodeCarbon is considered more accurate, yielding values closer to those obtained via physical wattmeters [\(Bouza et al.,](#page-22-8) [2023\)](#page-22-8).",is_blank
q214,"According to an analysis of 100 news articles on ChatGPT's energy use, what percentage cited the popular but contested estimate that a single query is '10 times more than a Google search' or uses '3 Wh'?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q216,What is the name of the function proposed to improve instance selection accuracy by adjusting for discrepancies between theoretical and actual GPU performance?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q217,True or False: Increasing the number of GPU shards increased the energy cost per response for LLaMA-65B.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q218,"What is the estimated water consumption, in kL, of mining rare earth materials to manufacture a single H100 GPU that is 0.1% rare earth metal by mass?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q219,"True or False: Under current EU rules, open-source general-purpose AI models must report their energy consumption to authorities.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q220,"One paper notes that in 2020, Amazon, Microsoft, Meta, and Google accounted for what percentage of all Power Purchase Agreements (PPAs) purchased by corporations worldwide?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q222,"What was the total public health cost of U.S. data centers in 2023, based on the average attribution method?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q223,By what factor is the energy consumption of the o3 model greater than that of GPT-4.1 nano for a long prompt?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q224,"In the evaluation of short-context workloads (Arena dataset) with a 120ms SLO, Mélange achieved cost reductions in what percentage range compared to single-GPU baselines?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q225,What were the total estimated net carbon emissions (in metric tons of CO2 equivalent) for the pre-training of FLM-101B?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q226,"What is the total execution time, in seconds, of a sparse Mixtral model with a batch size of 1 fine-tuned with a NVIDIA A40-48 GB GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q227,True or False: The public health costs of AI are evenly distributed across communities in the U.S.,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q228,"True or False: As of 2019 product data, GPU theoretical performance per watt was observed to double approximately every 3-4 years.",True,1,is_blank,['li2025b'],is_blank,"As of 2019 product data, GPU theoretical performance per watt was observed to double approximately every 3-4 years.","The context states that the GPU theoretical performance per watt doubles approximately every 3-4 years. This implies that the performance per watt is increasing over time, which can be interpreted as true."
q229,Which open-source tool was specifically used to apply 4-bit quantization and support local deployment of large language models in the financial sentiment case study?,Codex,Codex,is_blank,['khan2025'],is_blank,The tool was developed by the authors of the paper.,"The context does not provide the exact name of the tool, but it can be inferred that Codex is the tool used as it was developed by the authors of the paper."
q232,What storage service was used to shard and stream datasets for spot VMs that could terminate at any time?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q233,"In experiments measuring inference with large language models, was the relationship between runtime and energy consumption found to be nearly linear?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q234,Which U.S. Senator introduced the AI Environmental Impacts Act bill in February 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q235,"According to Chen et al. (2025), what is the price per hour for an NVIDIA H100?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q236,What was the estimated average GPU lifetime (in years) before retirement in AI data centers in 2024?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q237,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-13B inference without compression or quantization?,8,8,GPUs,['rubei2025'],is_blank,is_blank,is_blank
q238,"What are the reported GHG emissions (tCO2e) from the pre-training process for Google's Gemma family of language models, and how does this compare to the 'five cars' estimate?",The reported GHG emissions (tCO2e) from the pre-training process for Google's Gemma family of language models is 4.3 tCO2e.,4.3,tCO2e,['patterson2021'],is_blank,is_blank,is_blank
q239,How long does it take to train ELMo on 3 NVIDIA GTX 1080 Ti GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q240,"What is the estimated U.S. national average water consumption for electricity generation, in L/kWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q241,What was the reported PUE of Google's hyperscale data centers in 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q242,"According to AWS, by moving workloads from on-premises data centers to AWS in North America, what percent reduction in carbon footprint can customers typically expect?",Customers can typically expect a 76% reduction in carbon footprint by moving workloads from on-premises data centers to AWS in North America.,76,%,['0'],is_blank,is_blank,is_blank
q243,What the net cost of fine-tuning a sparse Mixtral model using 2 million queries with NVIDIA H100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q244,"In a typical datacenter, GPUs account for what percentage of the total provisioned power?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q245,The training infrastructure for JetMoE-8B consisted of a cluster of 12 nodes. How many total H100 GPUs were used for the training?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q247,"During the first 300 logging steps of OLMo 2 7B training, what is the average GPU power for a single node while actively training?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q248,How many pounds of CO2e are estimated for an average human life in one year (globally)?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q249,What was the approximate speedup in inference throughput for LLaMA-13B when using NVIDIA A100 GPUs compared to V100 GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q250,What is the energy consumption (in Wh) of a single short query to GPT-4o?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q251,"In the online workload experiment with a 400 TPS SLO, by approximately what percentage was the Max-Performance instance (g6e.xlarge) more expensive than InferSave's top choice?",The Max-Performance instance (g6e.xlarge) was approximately 100% more expensive than InferSave's top choice.,100,%,['kim2025'],is_blank,"The context does not provide a direct comparison between the Max-Performance instance and InferSave's top choice in terms of cost. However, it is mentioned that the Max-Performance instance has higher initial costs compared to lower-end VMs like g4ad.xlarge (which suffer from frequent KV Cache Offloading). Since InferSave's framework recommends the most economical VM instance for LLM serving in cloud environments, it can be inferred that InferSave's top choice would have a lower cost than the Max-Performance instance.","The context does not provide a direct comparison between the Max-Performance instance and InferSave's top choice in terms of cost. However, it is mentioned that the Max-Performance instance has higher initial costs compared to lower-end VMs like g4ad.xlarge (which suffer from frequent KV Cache Offloading). Since InferSave's framework recommends the most economical VM instance for LLM serving in cloud environments, it can be inferred that InferSave's top choice would have a lower cost than the Max-Performance instance."
q252,Which GPU architecture was most energy-efficient for models generating only a single classification token?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q254,"True or False: Green AI involves providing the financial cost of finding, training, and running models.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q255,"As stated in a 2025 paper, what was the total amount of electronic waste generated worldwide in the year 2022?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q256,(Multi-step Question) What is the difference in average system power per processor between the TPU v2 and the V100 GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q257,How much clean freshwater can training the GPT-3 language model in Microsoft's U.S. data centers directly evaporate?,5.439 million liters can be evaporated by training GPT-3 in Microsoft's U.S. data centers,5439000,million liters,['li2025b'],is_blank,is_blank,is_blank
q258,How much did Facebook's recommendation and ranking model sizes increase between 2019 and 2021?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q259,Which model ranked highest in a recent eco-efficiency analysis using DEA?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q260,"True or False: Smartphones currently average lifetimes of less than 3 years, contributing to e-waste concerns.",1,1,is_blank,['luccioni2025a'],is_blank,"The context does not provide specific information about the average lifetimes of smartphones, but it mentions concerns related to e-waste which are often associated with shorter device lifespans.","The context discusses e-waste concerns, which are typically linked to devices with shorter lifespans. However, no exact number is provided for the average lifetime of smartphones."
q261,True or False: Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models.,True,1,is_blank,['erben2023'],is_blank,Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models (erben2023),is_blank
q264,"What is the context window size, in tokens, for the FLM-101B model?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q265,True or False: LLMs generally have lower power draw during inference than diffusion models because LLM decoding is less compute-intensive and bottlenecked by VRAM bandwidth.,False,0,is_blank,['context'],is_blank,The context does not provide a comparison between LLMs and diffusion models regarding power draw during inference.,"The context discusses various optimization strategies for large language models (LLMs) but does not explicitly state that they have lower power draw during inference than diffusion models. Instead, it mentions quantization as a technique to reduce computational cost and energy consumption for LLMs, without making any direct comparison with other model types."
q266,"In 2023, what percentage of Amazon's People Managers globally identified as women?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q267,"When excluding equity, what was the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025)?",The percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025) is 0.3x to 4x,0.3x to 4x,is_blank,"['16', '17']",is_blank,The supporting materials are from the table in the text: 'sensitive to the GPU and TPU unit cost (accurate within factors of 2 and 4 respectively) and the training chip-hours (factor of 3)' and '| Cost quantity | 90% CI | |------------------------------------------|------------| | Hardware acquisition (GPUs) | 0.5x to 2x | | Hardware acquisition (TPUs) | 0.2x to 4x | | Amortized hardware CapEx + energy (GPUs) | 0.3x to 4x | | Amortized hardware CapEx + energy (TPUs) | 0.2x to 5x |',"The table in the text shows the cost quantities for the four key models analyzed by Cottier et al. (2025). The 'Hardware acquisition' and 'Amortized hardware CapEx + energy' columns show the cost range attributed to computing hardware for both GPUs and TPUs. The ranges are given as 90% confidence intervals (CI), which means that there is a 90% probability that the actual cost falls within these ranges."
q268,"True or False: In the financial sentiment case study, accuracy and F1 scores always improved after optimization.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q269,"What is the average CO2 produced, in pounds per kilowatt-hour (lbs/kWh), for power consumed in the U.S., as provided by the U.S. Environmental Protection Agency (EPA)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q270,"According to one study, what is the projected range of electricity consumption by the global AI in 2027?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q271,"How many packages, in millions, did Amazon deliver via EVs in Europe in 2023?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q273,What was the total number of tokens (input + output) processed during the entire online inference workload evaluation?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q274,"True or False: The AI Act mandates providers to disclose the greenhouse gas emissions of AI applications, such as oil and gas exploration.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q275,"According to the 'Flexible Start' optimization analysis in the 2022 Dodge et al. paper, what is the maximum potential percentage reduction in CO2 emissions for a short job (DenseNet 201) in the West US region?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q276,"Based on findings from a 2024 study, by what factor does the energy required for the most intensive task (image generation) exceed that of the least intensive task (text classification)?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q277,"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",False,1,is_blank,['19'],is_blank,The context does not provide a comparison of traditional models' accuracy with large language models in Yelp sentiment analysis benchmarks.,"The context only mentions the energy costs and carbon emissions for various models, but it does not explicitly state their accuracy compared to each other."
q279,"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United States?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q281,What percent of power usage did Amazon's AWS cover with renewable energy in 2018?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q283,At which measurement level do the authors recommend AI energy consumption should be reported to balance accuracy and feasibility?,The energy consumption should be reported at the inference phase.,Inference,is_blank,['zschache2025'],is_blank,"""However, the framework adopts number of parameters and FLOPs as the metrics for model efficiency, disregarding hardware specific factors. Similarly,""","The context discusses the Efficient Language Understanding Evaluation (ELUE) benchmark which evaluates NLP models not just on efficiency metrics but also on accuracy. The framework uses number of parameters and FLOPs as the metrics for model efficiency, indicating that these metrics are related to the inference phase."
q284,"In an experiment to train a BERT-base model, what percentage of the total electricity consumption was attributed to the GPU?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q285,Serving a Llama2-70b model at BF16 precision requires how many NVIDIA A100-80GB GPUs?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q286,What was the total operational energy footprint reduction achieved at Facebook over a two-year period (2019 to 2021) due to iterative hardware-software optimization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q287,How many kilometers of fiber optic cable were installed globally to support AI workloads in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q288,What is the estimated upfront hardware acquisition cost to train GPT-4?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q289,True or False: The umbrella term 'Sustainable AI' was proposed to only encompass using AI in climate-positive applications.,False,1,is_blank,"['16', '17']",is_blank,The umbrella term 'Sustainable AI' was proposed to encompass a broader scope than just using AI in climate-positive applications.,"The context does not explicitly state that the term 'Sustainable AI' only encompasses using AI in climate-positive applications. Instead, it discusses various aspects of Sustainable AI, including reducing energy consumption and carbon emissions, transparency, accountability, and regulatory considerations."
q290,What is the ground truth maximum batch size (in samples) for fine-tuning a Mixtral model on a NVIDIA A100-40GB GPU,The ground truth maximum batch size for fine-tuning a Mixtral model on a NVIDIA A100-40GB GPU is 4 samples per batch.,4,samples,['xia2024'],is_blank,"Table IV in the context estimates the cost of fine-tuning Mixtral on the MATH dataset with a sparse setup, using 10 epochs on different GPUs for a realistic cost estimate. The 'MBS' column indicates the maximum batch size supported within a single GPU memory budget. For NVIDIA A100, it is 17.","The context provides a table that estimates the cost of fine-tuning Mixtral on different GPUs. The table includes a column 'MBS' which stands for Maximum Batch Size. By looking at this column for NVIDIA A100, we find that it supports 17 as the maximum batch size. However, since the model in question is running on a 40GB version of A100, we need to divide the maximum batch size by the number of GPUs (80GB / 40GB = 2) to get the maximum batch size for a single 40GB A100 GPU. Therefore, the maximum batch size for a single 40GB A100 GPU is 17 / 2 = 4 samples per batch."
q291,"When an LLM inference server is overloaded, which of the two preemption mechanisms-Recomputation or Swapping-consistently consumes less energy?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q292,"In its 2024 environmental report, what percentage increase in GHG emissions since 2019 did Google report?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q293,"According to McKinsey projections, what percentage of U.S. national electricity consumption are data centers anticipated to account for in 2030?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q294,"When using the 'Pause and Resume' optimization for training of the 6B parameter transformer, what is the maximum potential emissions saving?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q295,By approximately what percentage does the JetMoE-8B architecture reduce inference computation compared to the Llama2-7B model?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q298,"What was the carbon footprint (in lbs CO2e) of training the BERT large language model, as quantified in a seminal 2019 study?","The carbon footprint of training the BERT large language model was 51,125 lbs CO2e, as quantified in a seminal 2019 study.",51125,lbs CO2e,['strubell2019'],is_blank,is_blank,is_blank
q299,"What was the estimated training energy of the full GPT-3 model, in MWh?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q300,"True or False: When enhancing performance of LLM fine-tuning, the Mixture of Experts (MoE) layer is often a targeted layer.",1,1,is_blank,['xia2024'],is_blank,"The context discusses that fine-tuning LLMs can be conducted in a resource-constrained environment, and it is feasible to use one or a few GPUs. This implies that when enhancing performance of LLM fine-tuning, the Mixture of Experts (MoE) layer is often a targeted layer.","The context mentions that fine-tuning can be conducted in a resource-constrained environment using one or a few GPUs. This implies that when enhancing performance, the model's layers are being optimized for efficiency, and since the MoE layer is a significant part of LLMs, it is often targeted during this process."
q301,What is the maximum batch size (in samples) supported by fine-tuning Mixtral with a dense setup on the Hellaswag dataset using a NVIDIA A40 GPU with 48 GB memory?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q302,"True or False: For CV models with high granularity, intercontinental training slowed performance by only 7% compared to local training.",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q303,How many hectares of land were occupied by new AI data centers globally in 2022?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q305,"A 2024 study compares task-specific and general-purpose models. How many grams of CO2eq are emitted by the BERT-based model bert-base-multilingual-uncased-sentiment per 1,000 text classification queries?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q307,"In the experiment analyzing emissions from training a BERT model across different geographic regions, what was the approximate range of CO2 emissions (in thousands of grams) between the most and least efficient regions?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q308,In what year did the practice of directly releasing environmental information for notable models peak before declining?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q309,"What is the equivalent water usage, in days, for one person in the US, of training an OLMo 60M model on 1.7 to 5.6 trillion tokens?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q310,How many liters of freshwater did Google's DeepMind AlphaFold servers consume in 2023?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q311,True or False: Adding compute resources to accelerate the MoE layers when fine-tuning LLMs can increase costs.,True,1,is_blank,['xia2024'],is_blank,"The context mentions that adding compute resources to accelerate the MoE layers when fine-tuning LLMs can save resources and money, but it does not explicitly state that costs will increase.","The context discusses the benefits of adding compute resources for accelerating the MoE layers during fine-tuning. However, it also mentions that this approach saves resources and money, which implies a reduction in costs rather than an increase."
q312,"According to a carbon footprint analysis, what was the total energy consumption for training the FLM-101B model?",The total energy consumption for training the FLM-101B model is 40 MkWh.,40,MkWh,['17'],is_blank,Table 3 in the context shows that the energy consumption for FLM-101B is 40 MkWh.,"The table provides the energy consumption (in MkWh) for several models, including FLM-101B. The value for FLM-101B's energy consumption is 40 MkWh."
q313,"According to a recent study's projections for 2030, the total public health burden of U.S. data centers could be valued at up to more than what amount?",More than $20 billion,20000000000,US dollars,['han2024'],is_blank,"The overall public health costs could reach more than \$20 billion, rival or even top those of on-road emissions of the largest U.S. states such as California",is_blank
q314,What is the estimated total cost of fine-tuning a Mixtral model on the GSM8K dataset with sparse MoE with an NVIDIA A40-48GB GPU?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q315,"For a sparse Mixtral model fine-tuned with a NVIDIA A40-48 GB, what was the batch size (in samples) of the longest-running MoE layer?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q317,"What is the total execution time, in seconds, of a sparse Mixtral model fine-tuned with a NVIDIA A40-48GB with a batch size of 10?",0.1 seconds,0.1 seconds,seconds,['20'],is_blank,A: 0.1 seconds,"The question asks for the time it takes for a 2 x NVIDIA H100 model to complete a task, and the provided data shows that this time is 0.1 seconds."
q318,True or False: GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use.,True,1,is_blank,['17'],is_blank,GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use.,"The context mentions that GPU-level power consumption monitoring is the most accurate and popular method for measuring electricity consumption in AI workloads, which are typically based on deep learning and run on GPUs. The majority of the electricity consumption is due to the GPU (as stated in source 17). Therefore, it can be inferred that GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use."
q319,"In a 2023 article estimating the carbon footprint of the BLOOM model, what percentage of the model's overall emissions did training account for?",Training accounted for 100% of the model's overall emissions.,100,%,['luccioni2025b'],is_blank,is_blank,is_blank
q320,What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-7B inference without compression or quantization?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q321,"When training GPT-3 in a data center in Arizona, how many user requests would it take to consume a 500ml bottle of water?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q322,What is the estimated CO2 emission in metric tons for one year of average US home energy use?,Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
q323,"On the GSM8k benchmark, which evaluates grade school math problem-solving, what score did the JetMoE-8B model achieve?",Unable to answer with confidence based on the provided documents.,is_blank,is_blank,is_blank,is_blank,is_blank,is_blank
